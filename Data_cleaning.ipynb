{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acc96842-f662-4961-9db8-4061f573e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "from re import sub\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange \n",
    "import random \n",
    "import multiprocessing\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6caeb59-c424-4802-9cae-57c63b102992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3421a41-fd3b-47ad-b9c7-284604c3f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ebb3c3-a36e-47d5-9970-176d583aa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ae95bc-8934-49c9-8ba1-0a82e651a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"elonmusk_2021-11-26.csv\", index_col = False)\n",
    "tweets = tweets.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f725c15d-b5fc-41a8-a513-6a56d63c50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.sort_values(by=['Datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a5ed00-04d3-47ec-95ba-9b1b9f20e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using clean to remove the emojis from all tweets \n",
    "def clean_text(x): \n",
    "    x = clean(x, no_emoji=True)\n",
    "    return x \n",
    "\n",
    "def remove_stop_word(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \" \", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.split()\n",
    "    word_list = [w for w in text if w not in stop_words] \n",
    "    return word_list\n",
    "        \n",
    "\n",
    "# tweets.Text = tweets.Text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b4ecd97-f1dd-4fd4-9dfc-c1e8f54bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Word_List\"] = tweets.Text.apply(remove_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b52c72fa-c35e-4cc9-b021-4a917517a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(tweets.Word_List, min_count=1, progress_per=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "232a031a-1c50-48aa-a2e6-8ec28b142e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "365729a2-fac6-490f-aab7-bff57cf90884",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[tweets.Word_List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975b837-5240-4b59-bcad-534775de55a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18c9b1ee-77dd-4440-ad89-3a37d57638e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.01 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuwa\\AppData\\Local\\Temp\\ipykernel_15956\\854251204.py:19: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "w2v_model.vector_size = 300\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000) \n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay = 1)\n",
    "\n",
    "print(\"Time to train the model: {} mins\".format(round((time() -start)/ 60,2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da5b06f8-47b3-4b78-ae10-74088006e445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  dropping friends pool\n",
       "1                                          splish splash\n",
       "3            dayquil plus nyquil https_//t co/aadssrmjyf\n",
       "4           blow_whistle tesla ! https_//t co/c86hla0iqk\n",
       "5      waste money silly apple cloth buy whistle inst...\n",
       "                             ...                        \n",
       "924    tesla full self_driving beta available anyone ...\n",
       "925    might notice small sometimes major improvement...\n",
       "926    people_spoken amnesty begins next week vox_pop...\n",
       "927    thanksgiving cuisine delightful symphony flavor !\n",
       "928                                  think culture war ?\n",
       "Name: Word_List, Length: 919, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tweets.Word_List\n",
    "temp.apply(lambda x: ' '.join(bigram[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a32ebdce-77a1-487a-936b-2307534728ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuwa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "word_vectors = w2v_model.wv\n",
    "model_k = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors)\n",
    "positive_cluster_center = model_k.cluster_centers_[0]\n",
    "negative_cluster_center = model_k.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e916666-fb21-47ae-b3a6-3dcd379ad27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01012455,  0.01852418,  0.01101304, -0.00629772, -0.00051504,\n",
       "        -0.01141429, -0.02486277,  0.01309604, -0.00254958,  0.02233625,\n",
       "        -0.0176393 , -0.02761401,  0.00590977,  0.01542205,  0.00283082,\n",
       "         0.00271091,  0.00893688,  0.00238325,  0.04406161,  0.00444396,\n",
       "         0.00363386, -0.00409851,  0.01738828,  0.00671896,  0.00194588,\n",
       "         0.01303354,  0.00647307,  0.00278872, -0.00961589,  0.00563234,\n",
       "         0.01205131, -0.01227917,  0.00764619, -0.00765575, -0.01920667,\n",
       "        -0.00739408,  0.00921538, -0.00232113,  0.02245195, -0.0094457 ,\n",
       "        -0.00875925, -0.00252103, -0.01987667, -0.01472505, -0.01915696,\n",
       "         0.00460049, -0.00573168, -0.00503451,  0.00221537, -0.01944723,\n",
       "         0.01280442,  0.00319751, -0.01669665, -0.00462169,  0.00611876,\n",
       "         0.00623939, -0.00799015,  0.00145962, -0.02098984,  0.0066717 ,\n",
       "        -0.00784816, -0.00961786, -0.01638368,  0.01417754,  0.01959795,\n",
       "        -0.00733548,  0.0188224 , -0.01913453, -0.00464258,  0.02410112,\n",
       "        -0.00537367, -0.00268749, -0.02333979, -0.01664175, -0.00630843,\n",
       "         0.00918899, -0.03465338, -0.00547325,  0.01244452,  0.02053391,\n",
       "        -0.01207951, -0.0186509 ,  0.00226614,  0.01870767, -0.0088604 ,\n",
       "         0.01472938, -0.00593282,  0.01676272,  0.0103199 , -0.01605911,\n",
       "         0.02981501, -0.01588193, -0.02455669, -0.01557278, -0.00527197,\n",
       "         0.00314367,  0.00015479, -0.00883945, -0.00734505, -0.00834376],\n",
       "       [-0.00484523,  0.0001482 , -0.0055659 ,  0.00780103, -0.01209735,\n",
       "        -0.01027405,  0.02734115,  0.00480378, -0.00030975, -0.01834201,\n",
       "         0.00468561,  0.01307749, -0.00447072, -0.01069171, -0.00378268,\n",
       "        -0.01650034, -0.00179074, -0.01823252, -0.03632782, -0.01771633,\n",
       "         0.00440388,  0.01459003, -0.00370169, -0.01882058, -0.0018748 ,\n",
       "        -0.00553193, -0.01059636, -0.02788478, -0.01885575, -0.00053506,\n",
       "         0.00293405,  0.01378599, -0.00010501,  0.00687216,  0.00353288,\n",
       "         0.0204376 , -0.01283211, -0.01131053, -0.02771813, -0.02479834,\n",
       "         0.01088942, -0.00514708,  0.00762608, -0.0035273 ,  0.02324404,\n",
       "        -0.0149383 , -0.00084937,  0.01152128,  0.00458464,  0.00986156,\n",
       "         0.00872581, -0.02155827,  0.0123894 ,  0.00931729, -0.02087279,\n",
       "         0.00426468,  0.00737547, -0.00321205, -0.01031401, -0.00717084,\n",
       "         0.00419799,  0.0129716 ,  0.00167748, -0.02268893, -0.03547003,\n",
       "         0.01006023, -0.0010621 ,  0.01089405, -0.01876631, -0.00738603,\n",
       "        -0.0066357 , -0.00223202,  0.03127182,  0.00546795,  0.00650231,\n",
       "         0.00452839,  0.02402292, -0.01379202, -0.01947545,  0.00203853,\n",
       "         0.00533002,  0.005198  , -0.00975893,  0.00838631, -0.00084829,\n",
       "         0.00398872, -0.00993474,  0.01285624,  0.00484166,  0.00580126,\n",
       "        -0.00084359,  0.02252291,  0.00705522,  0.01089755,  0.02598253,\n",
       "         0.01558334, -0.00277381, -0.01451681,  0.01446363,  0.00070445]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_k.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e71cd61b-3476-42f2-9f9f-6557346d8a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anyone', 0.3554791510105133),\n",
       " ('raptor_2', 0.3015036880970001),\n",
       " ('list', 0.29193463921546936),\n",
       " ('great_work', 0.28133854269981384),\n",
       " ('spacex', 0.28007304668426514),\n",
       " ('tweet', 0.27449506521224976),\n",
       " ('rocket', 0.2713889181613922),\n",
       " ('almost', 0.2688022553920746),\n",
       " ('ukraine', 0.26417335867881775),\n",
       " ('voice', 0.2615019679069519)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model_k.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07513e4-2020-4323-a99f-c9dbc8dda473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e680e1e0-aa7d-413e-8a1e-512030090af3",
   "metadata": {},
   "source": [
    "## Cleaning Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84a6b0a8-7edf-419e-9fd7-9c6ae47fbdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index(drop=True)\n",
    "# df = df.drop(df[df.score < 50].index)\n",
    "tweets = tweets.drop(tweets[tweets.Text == \"\"].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d02e8ad-44a7-4856-8e98-81f77686f483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-29 23:52:29+00:00</td>\n",
       "      <td>1465468742570229767</td>\n",
       "      <td>just dropping some friends off at the pool</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-30 00:13:51+00:00</td>\n",
       "      <td>1465474116622946307</td>\n",
       "      <td>splish splash</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-30 22:59:18+00:00</td>\n",
       "      <td>1465817742632792065</td>\n",
       "      <td>dayquil + nyquil https://t.co/aadssrmjyf</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-01 00:23:05+00:00</td>\n",
       "      <td>1465838829370228737</td>\n",
       "      <td>blow the whistle on tesla!\\nhttps://t.co/c86hl...</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-01 00:36:14+00:00</td>\n",
       "      <td>1465842137392680963</td>\n",
       "      <td>don't waste your money on that silly apple clo...</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet ID  \\\n",
       "0  2021-11-29 23:52:29+00:00  1465468742570229767   \n",
       "1  2021-11-30 00:13:51+00:00  1465474116622946307   \n",
       "3  2021-11-30 22:59:18+00:00  1465817742632792065   \n",
       "4  2021-12-01 00:23:05+00:00  1465838829370228737   \n",
       "5  2021-12-01 00:36:14+00:00  1465842137392680963   \n",
       "\n",
       "                                                Text  Username  \n",
       "0         just dropping some friends off at the pool  elonmusk  \n",
       "1                                      splish splash  elonmusk  \n",
       "3           dayquil + nyquil https://t.co/aadssrmjyf  elonmusk  \n",
       "4  blow the whistle on tesla!\\nhttps://t.co/c86hl...  elonmusk  \n",
       "5  don't waste your money on that silly apple clo...  elonmusk  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43dad1e9-2879-49f0-af63-d669643ce4df",
   "metadata": {},
   "source": [
    "# Deep NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e82c3e04-64e1-4e1e-a471-8f12a3d9eb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3fa06199474fb99ed2b3ae1650339e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuwa\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bhuwa\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d23e66065664d89be5b7cd0e9d4710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57568a1b523c4b8faf816b2bc2d63e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fac0ded-bbf1-4e1d-8462-6f6237b85388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c2949b-2a05-42f8-bbd5-92165df89b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:3100\u001b[0m, in \u001b[0;36mLayer._split_out_first_arg\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3098\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fn_args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   3099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3100\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3101\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe first argument to `Layer.call` must always be passed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, args, kwargs\n",
      "\u001b[1;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c7bba-5f51-4188-92dd-a6c8a49d7c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
