{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acc96842-f662-4961-9db8-4061f573e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "from re import sub\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange \n",
    "import random \n",
    "import multiprocessing\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6caeb59-c424-4802-9cae-57c63b102992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3421a41-fd3b-47ad-b9c7-284604c3f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17ebb3c3-a36e-47d5-9970-176d583aa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45ae95bc-8934-49c9-8ba1-0a82e651a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"elonmusk_2021-11-26.csv\", index_col = False)\n",
    "tweets = tweets.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f725c15d-b5fc-41a8-a513-6a56d63c50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.sort_values(by=['Datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48a5ed00-04d3-47ec-95ba-9b1b9f20e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using clean to remove the emojis from all tweets \n",
    "def clean_text(x): \n",
    "    x = clean(x, no_emoji=True)\n",
    "    return x \n",
    "\n",
    "def remove_stop_word(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \" \", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.split()\n",
    "    word_list = [w for w in text if w not in stop_words] \n",
    "    return word_list\n",
    "        \n",
    "\n",
    "# tweets.Text = tweets.Text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b4ecd97-f1dd-4fd4-9dfc-c1e8f54bdee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Word_List\"] = tweets.Text.apply(remove_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b52c72fa-c35e-4cc9-b021-4a917517a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(tweets.Word_List, min_count=1, progress_per=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "232a031a-1c50-48aa-a2e6-8ec28b142e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "365729a2-fac6-490f-aab7-bff57cf90884",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[tweets.Word_List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18c9b1ee-77dd-4440-ad89-3a37d57638e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.01 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuwa\\AppData\\Local\\Temp\\ipykernel_11132\\854251204.py:19: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "w2v_model.vector_size = 300\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000) \n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay = 1)\n",
    "\n",
    "print(\"Time to train the model: {} mins\".format(round((time() -start)/ 60,2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da5b06f8-47b3-4b78-ae10-74088006e445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928                                dropping friends pool\n",
       "927                                        splish splash\n",
       "926                                                     \n",
       "925          dayquil plus nyquil https_//t co/aadssrmjyf\n",
       "924         blow_whistle tesla ! https_//t co/c86hla0iqk\n",
       "                             ...                        \n",
       "4      tesla full self_driving beta available anyone ...\n",
       "3      might notice small sometimes major improvement...\n",
       "2      people_spoken amnesty begins next week vox_pop...\n",
       "1      thanksgiving cuisine delightful symphony flavor !\n",
       "0                                    think culture war ?\n",
       "Name: Word_List, Length: 929, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tweets.Word_List\n",
    "temp.apply(lambda x: ' '.join(bigram[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a32ebdce-77a1-487a-936b-2307534728ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuwa\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "word_vectors = w2v_model.wv\n",
    "model_k = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors)\n",
    "positive_cluster_center = model_k.cluster_centers_[0]\n",
    "negative_cluster_center = model_k.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e916666-fb21-47ae-b3a6-3dcd379ad27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01146346,  0.01488798,  0.01693169,  0.00333735, -0.00217718,\n",
       "        -0.00721252, -0.02699738,  0.01446479, -0.00935097,  0.02400909,\n",
       "        -0.02089914, -0.03029446,  0.00550795,  0.0205628 , -0.00220107,\n",
       "         0.0030316 ,  0.00514591, -0.00142077,  0.03283321,  0.01246648,\n",
       "        -0.00125937, -0.00296437,  0.01708045,  0.00562681, -0.00270615,\n",
       "         0.01371288,  0.00231122,  0.00459115, -0.00660328,  0.01286782,\n",
       "         0.01556407, -0.00692473,  0.01921166, -0.00997226, -0.02944162,\n",
       "        -0.00334534,  0.01559372,  0.00052092,  0.0127546 , -0.00779379,\n",
       "        -0.00309386,  0.00161669, -0.0188576 , -0.02002946, -0.01632452,\n",
       "         0.00926724,  0.0009747 , -0.01292452,  0.00811902, -0.01221974,\n",
       "         0.0118126 , -0.00226348, -0.01311588, -0.00454971,  0.00662278,\n",
       "         0.00983229, -0.01070018, -0.01124404, -0.03175205,  0.00304037,\n",
       "        -0.00538012, -0.00520442, -0.01326666,  0.01411611,  0.01959212,\n",
       "        -0.00337276,  0.02670472, -0.01966602, -0.00629681,  0.02779619,\n",
       "        -0.00485288, -0.00251107, -0.01412637, -0.00743882,  0.01001201,\n",
       "         0.00646733, -0.03362903, -0.00451763,  0.01975976,  0.0086336 ,\n",
       "        -0.0115697 , -0.01935799, -0.00110377,  0.02160915, -0.01032271,\n",
       "         0.01191956, -0.00942219,  0.00480113,  0.01192263, -0.00655818,\n",
       "         0.0330684 , -0.01634791, -0.02037726, -0.0144948 , -0.00911887,\n",
       "         0.00401701, -0.00057835, -0.00574935, -0.01243154, -0.00127734],\n",
       "       [ 0.00131906, -0.00039836, -0.0029933 ,  0.00114775, -0.0040657 ,\n",
       "        -0.01004094,  0.03011139,  0.01022211, -0.00022598, -0.01352506,\n",
       "         0.00328079,  0.00999939, -0.00107273, -0.01713626,  0.00449935,\n",
       "        -0.01428354, -0.00093024, -0.0212912 , -0.02322037, -0.02346047,\n",
       "         0.01042948,  0.01363696,  0.00275089, -0.0085625 , -0.00428902,\n",
       "        -0.00753147, -0.00806764, -0.02874717, -0.01963838, -0.00914173,\n",
       "        -0.00225295,  0.02095708, -0.01073372,  0.00886685,  0.00884138,\n",
       "         0.01530159, -0.02609866, -0.01871746, -0.02181467, -0.02337432,\n",
       "         0.00137248, -0.00451067,  0.01031686,  0.01056322,  0.02442707,\n",
       "        -0.01039663, -0.00922908,  0.00938778,  0.00134575,  0.01361768,\n",
       "         0.0133625 , -0.02068399,  0.00622922,  0.01079166, -0.01214534,\n",
       "        -0.00301338,  0.00902074,  0.00539553, -0.00768247,  0.00550007,\n",
       "        -0.00123585,  0.01515537, -0.00499717, -0.02149087, -0.04664093,\n",
       "         0.00590181, -0.00475635,  0.01711534, -0.01368227, -0.00649632,\n",
       "        -0.01144454, -0.00543531,  0.01989859,  0.00315494, -0.00163049,\n",
       "         0.00750929,  0.0261374 , -0.00633026, -0.0268935 ,  0.00760008,\n",
       "         0.00646693,  0.00342473, -0.00793914,  0.00854652, -0.00197422,\n",
       "         0.00823026, -0.00875954,  0.0159297 ,  0.00883773, -0.00170863,\n",
       "        -0.00575909,  0.0268618 ,  0.00286315,  0.01824422,  0.02537756,\n",
       "         0.01789146,  0.00294219, -0.01442724,  0.00411177,  0.00020023]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_k.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e71cd61b-3476-42f2-9f9f-6557346d8a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mention', 0.3219534158706665),\n",
       " ('use', 0.30631595849990845),\n",
       " ('team_making', 0.3022902309894562),\n",
       " ('great', 0.2996186912059784),\n",
       " ('tesla_ai', 0.29887640476226807),\n",
       " ('tesla_make', 0.2945714592933655),\n",
       " ('!', 0.29157179594039917),\n",
       " ('friend', 0.28394776582717896),\n",
       " ('tweets', 0.28337758779525757),\n",
       " ('10', 0.28198903799057007)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model_k.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a07513e4-2020-4323-a99f-c9dbc8dda473",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(list(word_vectors.index_to_key))\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model_k.predict(np.array(x).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b113fb13-ebf0-432c-819c-d5baa7f48d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [1]\n",
       "1      [0]\n",
       "2      [1]\n",
       "3      [1]\n",
       "4      [0]\n",
       "      ... \n",
       "436    [1]\n",
       "437    [1]\n",
       "438    [0]\n",
       "439    [0]\n",
       "440    [0]\n",
       "Name: cluster, Length: 441, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a68233dc-1670-49ba-87e8-5fda7d3e2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i == 0 else -1 for i in words.cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11662175-ced2-40d9-8a94-7cf2f8549b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['closeness_score'] = words.apply(lambda x: 1/(model_k.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5f8a58c-bc1a-4bf9-b523-40c663a3c593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = [\"!\", \"?\", \">\", \"<\", \"-\", \".\", \":\", \"@\", \"%\"]\n",
    "\n",
    "index_list = []\n",
    "\n",
    "for item in punctuation:\n",
    "    if len(words.index[words['words'] == item]) != 0:\n",
    "        index_list.append(words.index[words[\"words\"] == item][0])\n",
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d91f4ece-69e2-4b24-bef2-94538a106740",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_duplicate = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75499059-2932-46b3-89d4-61a19b42b9de",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[1, 4] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mword_duplicate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[1, 4] not found in axis'"
     ]
    }
   ],
   "source": [
    "word_duplicate.drop([1,4], axis=0, inplace=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a71107-5744-4fce-8702-1c62826ed814",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_duplicate.reset_index("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef044edd-3b51-4e4e-91b2-80c68743cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.to_csv(\"word_sentiment_coeff.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680e1e0-aa7d-413e-8a1e-512030090af3",
   "metadata": {},
   "source": [
    "## Cleaning Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84a6b0a8-7edf-419e-9fd7-9c6ae47fbdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index(drop=True)\n",
    "# df = df.drop(df[df.score < 50].index)\n",
    "tweets = tweets.drop(tweets[tweets.Text == \"\"].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dad1e9-2879-49f0-af63-d669643ce4df",
   "metadata": {},
   "source": [
    "# Deep NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c7bba-5f51-4188-92dd-a6c8a49d7c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
